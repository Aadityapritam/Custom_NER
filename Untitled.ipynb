{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path:\tarchive/Resumes/Abiral_Pandey_Fullstack_Java.docx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Name: Abiral Pandey Email: abiral.pandey88@gmail.com Phone: 940-242-3303 Current Location: Woonsocket, Rhode Island Visa Status: US Citizen SUMMARY: Dynamic individual with 6 years of software development experience in design, development, deployment, maintenance, production and support of web - based and Client-Server business applications using OOP and Java/J2EE technologies. Exposure to all phases of Software Development Life Cycle(SDLC) using Agile, RUP, Waterfall. Designed and developed web UI screen using Angular-JS. Developed AngularJS Controllers, Services, filters and directives for various modules in the application. Knowledge on ETL tools like Kettle Pentaho and Microsoft SSIS tools. Created custom directives, decorators and services using AngularJS to interface with both RESTful and legacy network services also DOM applications. Experience with MVC frameworks like Struts, SPRING and ORM tools like Hibernate. Experienced in working with batch jobs using Spring-Batch, Autosys and Quartz. Worked extensively with XML related technologies like XML/XSLT to process, validate, parse and extract data from XML using DOM and SAX parsers for DTD and SCHEMAand also worked with JAX-B. Strong experience in J2EE technologies like Java Beans, Servlets, JSP (including custom tags), JSTL, JDBC, Struts, Spring, JMS, JNDI and Multithreading. Expertise in web development technologies like HTML, DHTML, XHTML, CSS, Java Script, JQuery, JSF, AJAX, Bootstrap JS, Node JS and Angular JS. Experienced in RESTful web services using JAX-RS, Jersey framework and SOAP using JAX-WS, Axis-2 framework. Expert knowledge over J2EE Design Patterns like MVC, Adapter, Front End Controller, Value object, Singleton, Session Facade, Business Delegate, Factory DAO in designing the architecture of large applications. Experience in using Maven and Ant build scripts for the project build automation. Experience in using version control and configuration management tools like SVN, Clear Case and CVS. Expertise in working with various Application Servers such as IBM WebSphere, JBoss, Glassfish, Oracle WebLogic and Apache Tomcat server. Good knowledge in using IDE’s such as Eclipse, NetBeans, JBuilder, RAD and STS. Expertise in working with Relational databases such as Oracle, PostgreSQL, DB2, MySQL and NoSQL database MongoDB. Experience in database design using PL/SQL to write Stored Procedures, Functions, Triggers, views and good at writing complex queries for Oracle 10g/11g. Good experience in developing test cases with JUnit for Unit testing, Load testing and logging using Log4J. Experienced in using Operating Systems like Windows 98 / 2000 / NT / XP, AIX, Sun Solaris. Proficient in software documentation and technical report writing. Involved in Performance analysis and improvements of the application using tools like Jmeter and using commands on Unix box to resolve deadlocks and improve performance. TECHNICAL SKILLS: Programming Languages: Java/J2EE, PL/SQL, Unix Shell Scripts Java/J2EE Technologies: JavaBeans, collections, Servlets, JSP, JDBC, JNDI, RMI, EJB Frameworks: Struts 1.x/2.x, Spring 2.5/3.0, Web Framework, JSF, Hibernate, iBatis, JPA, Axis-2, Jersey Methodologies/Design Patterns: OOAD, OOP, UML, MVC, Singleton, DTO Pattern, DAO Pattern, Service Fa ade, Factory Pattern Build Automation: Jenkins, Maven, Ant Application/Web Servers: IBM Web Sphere 6.x/5.x, BEA Web Logic 8.1/9.1, Apache Tomcat 5.x/6.x, JBOSS 4.x/3.x XML processing: DTD, Schema, JAX-P (DOM, SAX), JAX-B Web Services: RESTful, SOAP Web Development: HTML, DHTML, XHTML, CSS, Java Script, JQuery, AJAX, LADP, JSF, Bootstrap JS, Node JS, Angular JS Version Control Tools: CVS, Harvest, IBM Clear case, SVN and GIT Databases: Oracle 9i/10g/11g, IBM DB2, SQL Server 2005/2008, PostgreSQL, MySQL, MangoDB Messaging Techologies: JMS, IBM MQ IDE s: Eclipse, NetBeans, RAD, WSAD Testing and Logging Frameworks: Junit, Log4j, Mockito, Finesse Tests Reporting Tools: Crystal Reports 11, Jasper Reports Tools: Rational Rose, MS Visio, XML Spy, TOAD Operating Systems: Windows 98/2000/NT/XP, AIX, Sun Solaris, HP-UX PROFESSIONAL EXPERIENCE: CVS, Woonsocket, Rhode Island                                 Full Stack Java Developer April 2016 – Present Responsibilities: Involved in various stages of Software Development Life Cycle (SDLC) deliverables of the project using the Agile methodology. Used AWS Cloud platform and its features which include EBS, AMI, SNS, RDS, EBS, Cloud Watch, Cloud Trail, Cloud Formation, Cloud Front, S3, and Route53.  Expertise in building rich, interactive user interfaces using HTML, CSS, JavaScript, jQuery, Node.Js and Angular.Js. Gathered and clarified requirements with business analyst to feed into high-level customization design, development and installation phases. Used Spring Framework for dependency injection for Action classes using Application Context XML file.  Involved in implementation of MVC pattern using JSP and Spring Controller. Developed business objects using Spring IOC, Spring MVC and Spring AOP. Implemented MVC architecture using JSP Spring, Hibernate and used Spring Framework to initialize managed beans and services. Implemented SOA architecture with Web Services using SOAP, JAX-WS, WSDL, UDDI and XML. Used Collections for Model classes in the DAO layer (Data Access Object) Involved in modifying some changes in DAO layer using Hibernate. Created mappings among the relations and written SQL queries using Hibernate. Implemented Concurrency, Exception Handling and Collections whenever necessary. Used Entity Beans to persist the data into IBM DB2 database like database access components, Creating Schemas and Tables. Used SQL to perform data mapping and backend testing, also documented all the SQL queries for future testing purpose. Created process flow for deploying application in Web Sphere application server. Managed build, reporting and documentation from the project information using Jenkins, Maven Tool and SVN for version control. Used Jenkins for Continuous Integration. Used JUnit for testing and used JIRA for tracking bugs. Responsible for the dealing with the problem, bug fixing and troubleshooting.  Environment: Java, J2EE, HTML, CSS, JavaScript, jQuery, Ajax, Spring, Spring IOC, Spring AOP, Spring MVC, Hibernate, REST, SOAP, XML, Eclipse, PL/SQL, JUnit, Maven Build Tool, DB2, JIRA, Jenkins, SVN and IBM Web Sphere, AngularJS, EBS, AMI, SNS, RDS, Cloud Watch, Cloud Trail, Cloud Formation, Auto scaling Toll Brothers, Horsham Township, Pennsylvania                  Software Engineer December 2015 -  March 2016 Responsibilities: Developed JSP and extensively used tag libraries.  Designed the system with OOAD methodology using various design patterns like factory method, Singleton, Adaptor, Template etc.  Implementing and planning the server-side architecture using Spring and Hibernate  Configured the spring framework for entire business logic layer with XML bean configuration files.  Preparation of Low Level Designing and High Level Designing and relevant documentation.  Extensively used Spring IOC for Dependency Injection and worked on Custom MVC Frameworks loosely based on Struts  experienced in build tools like Micro services, Ant, Maven and Gradle tools. Wrote Controller classes in Spring MVC framework in the web layer.  Produced the shopping cart on the client Front-end using jQuery, JavaScript, HTML5, CSS3.  Extensively used Eclipse based STS IDE for building, developing and integrating the application.  Used Table per hierarchy inheritance of hibernates and mapped polymorphic associations.  Developed one-much, many-one, one-one annotation based mappings in Hibernate.  Wrote queries Using Cassandra CQL to create, alter, insert and delete elements.  Developed DAO service methods to populate the domain model objects using hibernate.  Used java collections API extensively such as Lists, Sets and Maps.   Wrote DAO classes using spring and Hibernate to interact with database for persistence.  Developed components of web services (JAX-WS, JAX-RPC) end to end, using different JAX-WS standards with clear understanding on WSDL, SOAP using various message patterns   Performed on e-Commerce by using JSF framework and JavaScript, jQuery, HTML5 pages Wrote and tested Java Beans to retrieve trading data and subscriber's information from MySQL database server,  Extensive experience in Angular.JS for application implementation, proficient in creating modules, controllers, route-Providers, factory services, ng-repeat, customizable filter, http get/post methods and directives to realize functionalities like REST service with Ajax call , input validations, searchable and sortable contents.   Implemented Unit and Integration test cases with JUnit Framework based on Functional Flow.  Used tools like My Eclipse IDE, configured and deployed the applications onto Web Logic application server  Configured Log4j for logging and debugging   Environment: Eclipse, Java J2EE, HTML, JSP, JAX RPC, JAXB, CSS3, JavaScript, and jQuery, Spring MVC, Hibernate, RESTful web services, Apache Tomcat7.0, Cucumber, Cassandra, Junit, Jenkins, Maven, GitHub, XML, Log4j, EJB, MySQL, Ajax. Dairy Farmers of America, Kansas City, Missouri                      Java Developer November 2014 – December 2015 Responsibilities: Responsible for developing use cases, class and sequence diagram for the modules using UML and Rational Rose. Identifying and design of common interfaces across multiple systems or modules of social insurance. Developed the application using Spring Framework that leverages classical Model View Layer (MVC) architecture. UML diagrams like use cases, class diagrams, interaction diagrams (sequence and collaboration) and activity diagrams were used. Developed J2EE modules using XMI and CORE JAVA. Interaction with Business users for user and system acceptance testing. Validated the data against the business rules. Data access layer is implemented using Hibernate. Used Apache POI to generate Excel documents Implemented Struts action classes. Used Spring Security for Authentication and authorization extensively. Utilized Eclipse to create JSPs/Servlets/Hibernate that pulled information from a Oracle database and sent to a front end GUI for end users. Used JDBC for Oracle database connection and written number of stored procedures for retrieving the data. Developed modules for validating the data according to business rules and used Castor to convert data into array of XML strings and XSLT for transformation. Used Hibernate for data persistence. Developed SOAP based HTTP requests for communicating with Web Services. Was involved in the design of multi-tier architecture using EJB, Servlets and JSP. Used Spring Dependency Injection properties to provide loose-coupling between layers. Collaborated with Web designers to create the JSP pages, applying HTML, JavaScript, JQuery and Struts Tags. Extensively worked on debugging using Logging Frameworks such as Apache Log4j. Created test plans for unit testing to validate component functionality. Environment: Java 1.4.2, J2EE, Servlets, MVC, Web services, Struts, Spring - Core, MVC, Security, Eclipse, Hibernate, XML, XSLT, EJB, JSP, JDBC, JAX-B, JQuery, JavaScript, HTML, Log4j, Oracle 10g, Apache POI, Caster, XMI. Bank of Utah, Ogden, Utah                                                           J2EE Developer May 2013 – October 2014 Responsibilities: Designed and developed Servlets and JSP, which presents the end user with form to submit the details of the problem. Created SQL statements and triggers for the effective retrieval and storage of data from the database. Performed JUnit testing, proposed and implemented performance enhancements, worked with Oracle databases, running SQL scripts and stored procedures. Developed Restful based Web Services. Was involved in the design of multi-tier architecture using EJB, Servlets and JSP. Developed Servlets used to store user information in the database, which makes a JDBC-ODBC connection to the database and inserts the details into to the database. Designed and developed a Servlet, which presents the engineer a form to submit solution to particular problem. Setting up test environments and configuring various components of the application using JDBC API to establish a connection with oracle database and configuring. Designed and developed a Servlet, which allows the end user to query on the problem, makes a JDBC-ODBC connection to the database and retrieve the details regarding the call number and the status of the submitted problem. Environment: Java, J2EE, Servlets, JSP, EJB, Custom tags, JDBC, JUNIT, Restful, Data Source, DAO, VO Patterns, Tomcat 5.0, SQL, Oracle 9i, Linux. Epsilon, Irving, Texas                                                         Junior Java Developer January 2012 – April 2013 Responsibilities: Designed the user interfaces using JSP. Developed Custom tags, JSTL to support custom User Interfaces. Developed the application using Struts (MVC) Framework. Implemented Business processes such as user authentication, Account Transfer using Session EJBs. Used Eclipse to writing the code for JSP, Servlets, Struts and EJBs. Deployed the applications on Web Logic Application Server. Used Java Messaging Services (JMS) and Backend messaging for reliable and asynchronous exchange of important information such as payment status report. Developed the Ant scripts for preparing WAR files used to deploy J2EE components. Used JDBC for database connectivity to Oracle. Worked with Oracle Database to create tables, procedures, functions and select statements. Used JUnit Testing, debugging and bug fixing. Used Log4J to capture the log that includes runtime exceptions and developed WAR framework to alert the client and production support in case of application failures. Worked in Rational Unified Process (RUP) Methodology. Environment: Java, J2EE, JSP, JSTL, JDBC, Struts, EJB, JMS, Oracle, HTML, XML, Web Logic, Ant, CVS, Log4J, JUnit, JMS, PL/SQL, JavaScript, Eclipse IDE, UNIX Shell Scripting, Rational Unified Process (RUP). Education:  Bachelor of Computer Science – University of North Texas, Denton, Texas\""
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import docx2txt\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import io\n",
    "from os import listdir\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as fh:\n",
    "        # iterate over all pages of PDF document\n",
    "        for page in PDFPage.get_pages(fh, caching=True, check_extractable=True):\n",
    "            # creating a resoure manager\n",
    "            resource_manager = PDFResourceManager()\n",
    "            \n",
    "            # create a file handle\n",
    "            fake_file_handle = io.StringIO()\n",
    "            \n",
    "            # creating a text converter object\n",
    "            converter = TextConverter(\n",
    "                                resource_manager, \n",
    "                                fake_file_handle, \n",
    "                                # codec='utf-8', \n",
    "                                laparams=LAParams()\n",
    "                        )\n",
    "\n",
    "            # creating a page interpreter\n",
    "            page_interpreter = PDFPageInterpreter(\n",
    "                                resource_manager, \n",
    "                                converter\n",
    "                            )\n",
    "\n",
    "            # process current page\n",
    "            page_interpreter.process_page(page)\n",
    "            \n",
    "            # extract text\n",
    "            text = fake_file_handle.getvalue()\n",
    "            yield text\n",
    "\n",
    "            # close open handles\n",
    "            converter.close()\n",
    "            fake_file_handle.close()\n",
    "\n",
    "def extract_text_from_doc(doc_path):\n",
    "    temp = docx2txt.process(doc_path)\n",
    "    text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
    "    text= [line.replace('\\xa0', ' ') for line in temp.split('\\n') if line]\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "def main():\n",
    "    text=''\n",
    "    path=input('Enter the path:\\t')\n",
    "    if(path.split('.')[-1]=='pdf'):\n",
    "        for page in extract_text_from_pdf(path):\n",
    "            text += ' ' + page\n",
    "#         print(text)\n",
    "    elif(path.split('.')[-1]=='docx'):\n",
    "        text+=extract_text_from_doc(path)\n",
    "    return text\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path:\tarchive/Resumes/Adhi Gopalam - SM.docx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Adhi Gopalam'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name():\n",
    "    resume_text=main()\n",
    "    nlp_text = nlp(resume_text)\n",
    "    \n",
    "    # First name and Last name are always Proper Nouns\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    \n",
    "    matcher.add('NAME', [pattern])\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        return span.text\n",
    "    \n",
    "extract_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path:\tarchive/Resumes/Adhi Gopalam - SM.docx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Testing', 'Java', 'Database', 'Project manager', 'Salesforce']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# noun_chunks = nlp.noun_chunks\n",
    "\n",
    "def extract_skills():\n",
    "    resume_text=main()\n",
    "    nlp_text = nlp(resume_text)\n",
    "    noun_chunks=nlp(resume_text).noun_chunks\n",
    "    # removing stop words and implementing word tokenization\n",
    "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
    "    \n",
    "    # reading the csv file\n",
    "    data = pd.read_csv(\"skills.csv\") \n",
    "    \n",
    "    # extract values\n",
    "    skills = list(data.columns.values)\n",
    "    \n",
    "    skillset = []\n",
    "    \n",
    "    # check for one-grams (example: python)\n",
    "    for token in tokens:\n",
    "        if token.lower() in skills:\n",
    "            skillset.append(token)\n",
    "    \n",
    "    # check for bi-grams and tri-grams (example: machine learning)\n",
    "    for token in noun_chunks:\n",
    "        token = token.text.lower().strip()\n",
    "        if token in skills:\n",
    "            skillset.append(token)\n",
    "    \n",
    "    return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
    "\n",
    "extract_skills()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# import time\n",
    "# from random import randrange\n",
    "\n",
    "# refresh_time = 10\n",
    "# browser_list = []\n",
    "\n",
    "# browser_one = webdriver.Chrome(r\"C:\\Users\\Aaditya Raj\\Praemineo\\Process D\\chromedriver.exe\")\n",
    "# browser_two = webdriver.Chrome(r\"C:\\Users\\Aaditya Raj\\Praemineo\\Process D\\chromedriver.exe\")\n",
    "# browser_three = webdriver.Chrome(r\"C:\\Users\\Aaditya Raj\\Praemineo\\Process D\\chromedriver.exe\")\n",
    "\n",
    "# browser_list.append(browser_one)\n",
    "# browser_list.append(browser_two)\n",
    "# browser_list.append(browser_three)\n",
    "\n",
    "# for browser in browser_list:\n",
    "#     browser.get(\"https://www.youtube.com/watch?v=XtvpwEjtaIM\")\n",
    "\n",
    "# while(True):\n",
    "#      browser_num = randrange(0, len(browser_list))\n",
    "#      browser_list[browser_num].refresh()\n",
    "#      print(\"browser number\", browser_num, \"refreshed\")\n",
    "#      time.sleep(refresh_time)\n",
    "      \n",
    "# browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # l=[]\n",
    "# with open('data.json','r',encoding='utf8') as f:\n",
    "#     print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '\"Adhi Gopalam adhigopalam@gmail.com 281-212-3592 Certified Scrum Master and Business Analyst with over 12 years of experience in independently managing mid to large projects with experience in the Healthcare, Pharmaceutical (FDA Regulated), Banking and Retail industries Exceptional organizational, technical reporting, auditing/analysis and communication skills. Agile Project Management experience of the full project life cycle including requirements gathering, Scheduling and facilitating key agile ceremonies, velocity planning, obtaining and managing resources, conducting daily stand-ups, burn down charts, Product Demos, Retrospectives, Process documentation, managing budget, and facilitating project execution, deployment, and closure with a multicultural team in geographically distributed environments. One has consistently achieved strategic and tactical goals of the organization using strong technical, and management experience to improve delivery schedules and substantial reduction of costs. As a Project Manager, my responsibilities, while administering projects, included definition of the scope of the Project, Identifying and mitigating risks, periodically monitoring the performance of the project team, providing regular updates to the stakeholders that comprised of the Top Management, Line Managers and end users, mentoring and transfer of knowledge. The key to my success is the ability to provide solutions to complex challenges with clear communication between teams and stakeholders. Professional Strengths: Agile Project Management Scrum Master/Coach Resource Management Quality Assurance User Training Deployment of Best Practices Process re-engineering Technical Skills: Methodologies RUP, UML, Six Sigma, CMM, Waterfall, Agile, Sybase Power Designer, Joint Application Development (JAD), Unified Modeling Language (UML), Object Oriented Analysis and Design (OOAD) Change Management Tools Rational Clear Quest, Jira, SM7, ServiceNow SAP Module R/3, ECC & S4 HANA – SD, MM, EWM, RAR & SM Business Modeling Tools Rally, JIRA, Confluence, Rational Rose, Microsoft Visio. Project Management Microsoft Project, Microsoft Office, Rally, ALM MS Office Suite MS Word, MS Excel, MS PowerPoint Operating System Windows 95/98/2000/NT/XP/7/10 Agile Methodologies XP, Lean, SAFe 4.5, and DSDM Data warehouse tools BI/DWH, ETL, Informatica Power Centre Validations FDA’s regulations – CFR 21 Part 11, cGMP Project Experience: Black box Network, Pittsburgh, PA Jul ’17 - Present Scrum Master Project: BEST (SAP and ServiceNow Integration) Responsibilities: Working closely with the teams through agile events coaching on performing the activities, playing the roles and generating artifacts based on SAFe and Agile best practices Successfully migrated projects from Waterfall to Agile-Scrum and ensure team adopt agile way of working Trained teams in Agile, SAFe, Kanban, Confluence, and JIRA tool implementation Organized and facilitated Sprint planning, daily stand-ups, reviews, retrospectives, sprint/release planning, demos and other Scrum-related meetings Track and communicate team velocity and sprint/release progress with, and to all affected teams and management Involved in brainstorming sessions, analyzing the business processes, requirement gathering, Mapping the As-Is process and designing To-Be Processes Ensuring Implementation of TDD driven development related to WRICEFs and User Stories Analyzed the Product Backlog along with PO, performed ambiguity reviews and communicated the inconsistencies to the Configuration Team Constant coaching team on E2E process of Order Management related settings such as Order to Cash (OTC), Sales document types, Pricing Procedures, Item Categories, Schedule Lines, Outbound Delivery types, Contracts, Return Orders and Billing Management of the Test Data availability in Test environment through LSMW and BDC Played a key role in the planning User Accepted Testing (UAT) and implementation of system enhancements and conversions Work closely with other scrum teams to facilitate planning and execution of programs Ensured that the User Stories meet the INVEST principal (Independent, Negotiable, valuable, Estimable, Small, Testable) Created and maintained Sprint Burn-down Chart, Sprint Burn-up Chart and Product Burn-Down Chart to keep the track of the team\\'s progress and the team\\'s velocity for better estimation of the sprint life cycle Communicated the status of the Product Backlog Item to product Owner and external stakeholders on a regular basis Effectively involved in conducting Planning poker technique for estimating the User stories Helped the Product Owner to prioritize the Product backlog items (PBI\\'s) for developing Sprint tasks by taking suggestions from the cross-functional development team using Kano model Constantly connected with other scrum masters to share and learn experience to improve the velocity of team Helped the team stay focused by removing impediments, protecting them from distractions and keeping team meetings lean and efficient Created and maintained information tools: sprint board, burn-down charts, burn-up charts, progress dashboards, etc. Used JIRA for drafting the User Stories and managing the requirements and defects track Estimating backlog using T-shirt mechanism. Implementing Acceptance test based driven development (ATDD) development. Coordinating with TDM, BA for further backlog updates for different scrums. Discussion with all the stakeholders on architecture and Product backlog Environment: ServiceNow, Salesforce.com (SFDC), Kronos, ADP, SAP S4 HANA – MM, SD, SM, EWM, RAR, HR & FI/CO, SAP PI, FIORI, Web Services, JIRA & Blue works live Philips Healthcare, Baltimore, MD May ’08 – June 17 PM/Scrum Master Project: TeamSite (CMS), Salesforce (OneEMS), Hybris, TrackWise and CAPA Responsibilities: Collaborate, facilitate, lead and coach 3 scrum teams distributed among USA, Netherlands, and India while working on multiple project simultaneously. Successful Implementation and launch of mobile device program, for population health management (H2H) integrated with medical devices based in Bluetooth and IR connected devices Coaching team in value-based prioritization and challenge the norm, time to time to ensure focus is on delivering value. Coaching Product owner and team in writing effective user stories Develop and deliver organization-training materials and conducted workshops, Kaizen, building knowledge and skills to facilitate the agile transformation from waterfall software development. Continually coaching teams on Agile Scrum process while increasing quality and velocity Manage internal and external resources to optimize client impact within project budget, timeline and deliverables and agreed upon scope for TrackWise migration. Maintained Sprint & Kanban boards in JIRA and TFS to ensure sprint goals & milestones are being met Worked with several cross functional teams, often with conflicting priorities, to ensure timelines are met while also ensuring compliance to company policies and procedures Increasing the team\\'s agile fluency through coaching the team to embrace and embed lean and agile practices in their work Planned and facilitated various Scrum/Kanban meetings (Standup, sprint review, retrospective and planning) Ensure the development teams are practicing the core agile principles of collaboration, prioritization, team accountability, and visibility Facilitating discussion and conflict resolution, assisting with internal and external communication, improving transparency, and radiating information; Enabling the team to become self-organized and empowered teams that consistently deliver on their sprint commitments Managed progress of functional, system, integration, mobility, security and performance testing teams and monitor defects to bring it to closure Preparation of SoW with estimation of time, effort, cost and resources for manual and automation testing Managing multi-geographical distributed (onsite and offshore) agile scrum teams with the combination of FDA validation projects Utilized Agile Methodology to configure and develop process, standards, and procedures to create a Business Requirement Document (BRD) Identifying and assessing the risk, mitigating the risk, handling exceptions & problems Monitoring the project activities against the approved budget and schedule Managed content management system (CMS) migration project of Teamsite 7.2.1 to Teamsite 8.1 and later migrated to Adobe CQ5 Ability to use Six Sigma/lean methodologies combined with data analytic findings for business process improvement. Also used Six sigma tools for analysis activities Applied RUP methodology with its various workflows, artifacts and activities to manage life cycle from inspection to transition phase. Acted as liaison between external clients and SMEs to generate and standardize product requirements specification documents such as URS/FRS/Use Cases. Environment: MS Office, Rally, Team Foundation Server (TFS), Salesforce.com (SFDC), SAP CRM, Hybris, SoapUI, TeamSite (CMS), SAP ECC, Web Services, Doors, MS Project, HP ALM, QTP, and LoadRunner Bose Corporation, Stow, MA Nov ’07 – Apr ‘08 PM/Business Analyst Project: Demand Driven (D2 Supply Chain) Responsibilities: Responsible for the role of Project Manager and Scrum master for the Scrum teams in the project Lead Sprint planning, Sprint Reviews and Scrum of Scrums (SoS) for all the teams in the domain Coached the teams to be self-organizing and ensured the adherence of all the Scrum concepts and processes Ensured project\\'s adherence to Enterprise Agile Life cycle Developed automated metrics for Agile/Scrum for Executive Leadership team Supported projects by implementing Agile Life Cycle Management Tool – “Rally” to manage backlog and also helped to generate and analyze business metrics to be reported Agile Coaching - Release & Iteration Planning and Tracking. Conducted training on scrum, facilitated the daily standup, sprint review and sprint retrospective meeting Elicited requirements with business owner and converted business requirement into Use Cases. Conducted JAD sessions, interviews, and surveys to collect the requirements Conducted walk-through meetings with the off-shore development and QA team to elaborate requirements Managing the expectations and end results for all stakeholder groups involved in TeamCenter Unified implementation Elicited requirements with the stakeholders located across various countries and time zones Used Six Sigma Methodologies in solving the errors and issues while the development of the project. Maintained level 3 project plan to update daily status to manage all processes (OTC, FTM, STP & PTS) Developed and provided formal training and presentations/lectures to all UAT users ensuring an understanding of the dimensional model, metadata, and effective usage Managed the Item Proposal with Sales Order document types and Number ranges (internal and external) for all products Interacted closely with Configuration team to fix defects Conducted daily status/update meetings with all geographic team members (Local teams) Participated CAR review meeting for Unit and Integration testing Copy Controls for Sales Documents and Worked on Sales Inquiry, Quotation, Rush Order, Credit Process, and Free-of-charge Sample Sales order types testing Documented various phases of Quote-to-Cash, Purchase-to-Pay and Make-to-Order cycles Verified the integration of SD module with the FI and CO modules to make sure the right accounts are getting posted during AR and AP processes Verified the Configuration and Set up of Distribution Channels, Divisions, Sales Groups and Customer Groups as required. Managed and documented Item Proposal with Sales Order document types and Number ranges (internal and external) for various products. Supported Customization of Value Contracts, Service Contracts and Consignment Contract for a group of Companies including Mazda, Nissan Enterprises. Verified the configuration of Blocking/Unblocking of Sales types for specific customers. Interacted closely with UAT personnel to both ensure that their needs are met, and to provide sufficient Conducted project closure with milestones achieved, lessons learned, and project team member hours allocation review for business sponsor and product owners Environment: SCRUM - Agile methodologies, Waterfall, User Experience Design (UXD), Personas, MS Office (Excel, Visio, Project), TeamCenter PLM, HP Quality Center, SAP ECC,\\\\xa0QTP, SD, MM, FI/CO, Windows XP,\\\\xa0Ms Projects & Visio\\\\xa0 Health Net Systems, Naperville, IL \\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0 Nov ’06 – Oct ‘07 QA/Business Analyst Project: Oracle database migration \\\\xa0 Responsibilities: Participate in project design review meetings to prioritize and design the test documents.\\\\xa0 Worked closely with System Analysts, Project Leaders and developers to analyze the Business Requirements, Business Technical Specifications and Use Case Models. Responsible to write the test Plan and Test cases Responsible to run the queries in Issue Logs (Access) to track the status of open issues and delivers a Bug Report to the project team. Participate in bug review meetings. Re-test the testing issues and update the status in the issue log. Responsible to run the queries in Track Record to track the status of open issues and delivers a Bug Report to the project team. Responsible to manage (Track Record Admin) the Test Director Tool Coordinate with Automate QA team to write the scripts from scratch Worked closely with IT Team to test for new Clients client maintenance Worked closely with the project management on project delivery dates, scheduling bug fix promotions to test environment Interact with developers to prioritize/resolve the defects. Responsible to write and execute the End-to-End Test Plan. Worked closely with the User Acceptance Testing team to review the UAT issues and/or enhancements. Participate in project pre-implementation plan and post-implementation plan meetings. Participate in application demonstrations. Involved in design to automate the scripts Involved in upgrade Oracle from 9i to 10g Coordinate with third party vender to complete the code editing project Environment: Issue Log (Access), QA Director, Test Partner, Track Record,\\\\xa0Windows XP,\\\\xa0Java, Oracle 9i, Oracle 10g, Oracle Reports, Toad, Ultra Edit\\\\xa0 Other Companies worked in the past: Federal Reserve Bank of Richmond, VA Jul ’05 – Oct ‘06 Business Analyst Calamos Investments, IL Dec ’04 – Jun ‘05 QA Analyst Education: MBA from Vinayaka Mission, Salem, Tamilnadu, India. Pursuing MS in Security Systems from Southern New Hampshire University, US\"',\n",
       "  'entities': [[14787, 14809, 'Education', 38, 'rgb(232, 7, 8)'],\n",
       "   [14726, 14729, 'Education', 37, 'rgb(232, 7, 8)'],\n",
       "   [14662, 14685, 'Companies worked at', 40, 'rgb(92, 92, 131)'],\n",
       "   [14590, 14626, 'Companies worked at', 39, 'rgb(92, 92, 131)'],\n",
       "   [5772, 5791, 'Skills', 36, 'rgb(32, 185, 26)'],\n",
       "   [5642, 5654, 'Skills', 34, 'rgb(32, 185, 26)'],\n",
       "   [5627, 5633, 'Skills', 35, 'rgb(32, 185, 26)'],\n",
       "   [2264, 2283, 'Skills', 33, 'rgb(32, 185, 26)'],\n",
       "   [2203, 2216, 'Skills', 32, 'rgb(32, 185, 26)'],\n",
       "   [2193, 2201, 'Skills', 31, 'rgb(32, 185, 26)'],\n",
       "   [2164, 2191, 'Skills', 30, 'rgb(32, 185, 26)'],\n",
       "   [2139, 2155, 'Skills', 29, 'rgb(32, 185, 26)'],\n",
       "   [2101, 2137, 'Skills', 28, 'rgb(32, 185, 26)'],\n",
       "   [2084, 2099, 'Skills', 27, 'rgb(32, 185, 26)'],\n",
       "   [2069, 2082, 'Skills', 26, 'rgb(32, 185, 26)'],\n",
       "   [2057, 2067, 'Skills', 25, 'rgb(32, 185, 26)'],\n",
       "   [2011, 2049, 'Skills', 24, 'rgb(32, 185, 26)'],\n",
       "   [2006, 2009, 'Skills', 23, 'rgb(32, 185, 26)'],\n",
       "   [1982, 2000, 'Skills', 22, 'rgb(32, 185, 26)'],\n",
       "   [1955, 1980, 'Skills', 21, 'rgb(32, 185, 26)'],\n",
       "   [1950, 1953, 'Skills', 20, 'rgb(32, 185, 26)'],\n",
       "   [1944, 1948, 'Skills', 19, 'rgb(32, 185, 26)'],\n",
       "   [1898, 1942, 'Skills', 18, 'rgb(32, 185, 26)'],\n",
       "   [1855, 1897, 'Skills', 17, 'rgb(32, 185, 26)'],\n",
       "   [1822, 1853, 'Skills', 16, 'rgb(32, 185, 26)'],\n",
       "   [1785, 1820, 'Skills', 15, 'rgb(32, 185, 26)'],\n",
       "   [1755, 1760, 'Skills', 12, 'rgb(32, 185, 26)'],\n",
       "   [1744, 1753, 'Skills', 9, 'rgb(32, 185, 26)'],\n",
       "   [1739, 1742, 'Skills', 8, 'rgb(32, 185, 26)'],\n",
       "   [1728, 1737, 'Skills', 7, 'rgb(32, 185, 26)'],\n",
       "   [1723, 1726, 'Skills', 6, 'rgb(32, 185, 26)'],\n",
       "   [1704, 1721, 'Skills', 5, 'rgb(32, 185, 26)'],\n",
       "   [103, 125, 'Year of experience', 4, 'rgb(12, 79, 142)'],\n",
       "   [59, 92, 'Designation', 3, 'rgb(156, 105, 52)'],\n",
       "   [36, 48, 'Phone No', 2, 'rgb(171, 149, 113)'],\n",
       "   [14, 35, 'Email', 1, 'rgb(233, 157, 88)'],\n",
       "   [1, 13, 'Name', 0, 'rgb(37, 163, 185)']]},\n",
       " {'content': '\\xa0AADITYA RAJ Contact Address: A-281, Indravihar colony , Lalghati,462030,Bhopal,MP Mob: +917898864576 Email: aadityaraj.sistec@gmail.com Web: http://aaditya-blog.surge.sh/ LinkedIn: https://www.linkedin.com/in/a aditya-raj-a56426178/ Github: https://github.com/Aadityaprit am Objective A dedicated engineer passionate about cutting-edge technology and solving real-world problems with practical exposure. Looking forward to be associated with a dynamic and progressive organization that will allow me to utilize my abilities and qualifications to add value to the organization while providing me opportunities to grow. Work Exposure/ Internship Sep 2020 - Present Machine Learning Intern • Praemineo, Inc. [ I help Machine Learning & Deep Learning teams building scalable product with the cutting edge technologies best practices.] June 2020-sep 2020 Artificial Intelligence Intern at DAURINDIA TECHNOLOGY• Facial Recognition • Facial Verification [ Building Real-time Facial recognition & verification system for the employees of company using Convolutional neural network & OpenCV ] Sep 2019 -Jan 2020 Machine Learning Engineer • Chatbot Developer • Emphasis Corp [ Developed a chatbot for resolving normal IT-issues related to Pc and laptops using Dialogflow . Worked on a team of five member] Education Bachelor of Engineering - Sagar Institute of Science and Technology (SISTec), Bhopal 06/2017 – Present ➢ CGPA: 8.6 Higher Secondary - Trident Public School, Muzaffarpur,04/2015 –07/2017 ➢ Percentage: 74.8% Projects Dec 2020-Jan 2021 ➢ Custom Named Entity Recognition: Developed a System for the text recognition and tagging for custom type of text. Technologies used are- Natural Language Processing, Spacy, Deep Learning, Python. July 2020-July 2020 ➢ Damage Detection System: Detecting the various types of Damages like-Cracks, Bullseyes, Scratches, etc. using Yolo v3 & Deep Learning technology. This system helps in identifying the types of damage and localize them with the help of which, it becomes very easy to analyze the cost of rapairing. Senior Secondary – Emmanuel School, Motihari 04/2014 – 07/2015 ➢ CGPA: 10.0 Key Skills • Python • C • C++ • Machine Learning • Deep Learning • Data Science • Computer Vision • MySQL Database • SQL Lite • Flask • MongoDB May 2020-June 2020 ➢ Covid-19 Detection Using X-ray Image: Using X-ray Image ,this model/system predict whether it is positive or negative case with higher accuracy up to 96%, by analyzing X-ray image. March 2020- April 2020 ➢ Covid-19 Self Assessment System: Predict the %probability of getting infected or not. If result is positive, an automatic mail will be sent to given(health center email)mail . Moreover all the helpline or emergencies functionality are mentioned. Technology Used: Machine Learning, Flask Web: https://covid-19-self-assessment.herokuapp.com/ App: http://aadityapritam.thehacktivist.tech/ May 2020-June 2020 ➢ Emotion Detection & Classification Using Face Image Developed an Emotion Detection Deep Learning Model using Convolutional neural network to identify Happy or Sad using Person’s Image. Jan 2020 -April 2020 ➢ Auto-Image-Captioning : Describe or recognize the activity of image and provide an automatic caption to the given image Technology Used: Deep Learning(CNN) , Flask Oct 2019 -Dec 2019 ➢ Carrier-Consultancy-System: Suggest Job fields for Computer Science Students based on their skill quotients by recognize or extract skills from resume Technology Use: Machine Learning, Natural LanguageProcessing, Flask Sep 2019 -Sep 2019 ➢ Library Management System: A reliable Library System where all the records and functions is workable Technology Used: Python , File Management Certificates/Trainings ➢ Convolutional Neural Networks. ➢ A Crash Course in Data Science. ➢ Image Data Augmentation with Keras. ➢ IBM Certificate for Machine Learning using Python https://www.coursera.org/account/accomplishments/records/58W E27BYTNNZ ➢ Data Science Methodology certificate by Coursera https://www.coursera.org/account/accomplishments/certificate/V5 Q4W2S2DQGT ➢ Advance Python Training at SISTec ➢ Introduction To Python at Datacamp : https://www.datacamp.com/statement-ofaccomplishment/course/2b2ccbd2fbd3d6a91921907d243633d8e e9f2ccc Achievements • Code Gladiator 2019 Semifinalist . • Qualfied Google Codejam 2019 & 2020( Qualifier Round) • 98.37% skill quotient in python on Techgig • Gold Badge holder in 30days of code on Hackerrank https://www.hackerrank.com/aadityaraj_sist1 • Hackerearth https://www.hackerearth.com/@aaditya50 Area Of Interests • Deep Learning • Machine Learning • Data Science • Internet Of things(IOT) • Artificial Intelligence (AI) • Web Application Development Declaration I hereby declare that the above-mentioned information is correct up to my knowledge and I bear the responsibility for the correctness of the above-mentioned particulars. Signature (Aaditya Raj)',\n",
       "  'entities': [[2268, 2275, 'Skills', 26, 'rgb(32, 185, 26)'],\n",
       "   [2260, 2265, 'Skills', 25, 'rgb(32, 185, 26)'],\n",
       "   [2249, 2257, 'Skills', 24, 'rgb(32, 185, 26)'],\n",
       "   [2232, 2247, 'Skills', 23, 'rgb(32, 185, 26)'],\n",
       "   [2214, 2229, 'Skills', 22, 'rgb(32, 185, 26)'],\n",
       "   [2199, 2211, 'Skills', 21, 'rgb(32, 185, 26)'],\n",
       "   [2183, 2196, 'Skills', 20, 'rgb(32, 185, 26)'],\n",
       "   [2164, 2180, 'Skills', 19, 'rgb(32, 185, 26)'],\n",
       "   [2158, 2161, 'Skills', 18, 'rgb(32, 185, 26)'],\n",
       "   [2154, 2155, 'Skills', 17, 'rgb(32, 185, 26)'],\n",
       "   [1880, 1893, 'Skills', 13, 'rgb(32, 185, 26)'],\n",
       "   [1870, 1877, 'Skills', 12, 'rgb(32, 185, 26)'],\n",
       "   [1730, 1736, 'Skills', 16, 'rgb(32, 185, 26)'],\n",
       "   [1708, 1713, 'Skills', 15, 'rgb(32, 185, 26)'],\n",
       "   [1679, 1706, 'Skills', 14, 'rgb(32, 185, 26)'],\n",
       "   [1307, 1330, 'Education', 11, 'rgb(232, 7, 8)'],\n",
       "   [1152, 1165, 'Companies worked at', 8, 'rgb(92, 92, 131)'],\n",
       "   [1104, 1129, 'Designation', 9, 'rgb(156, 105, 52)'],\n",
       "   [885, 905, 'Companies worked at', 7, 'rgb(92, 92, 131)'],\n",
       "   [851, 881, 'Designation', 10, 'rgb(156, 105, 52)'],\n",
       "   [690, 705, 'Companies worked at', 6, 'rgb(92, 92, 131)'],\n",
       "   [645, 663, 'Year of experience', 5, 'rgb(12, 79, 142)'],\n",
       "   [634, 644, 'Designation', 4, 'rgb(156, 105, 52)'],\n",
       "   [109, 136, 'Email', 3, 'rgb(233, 157, 88)'],\n",
       "   [88, 101, 'Phone No', 2, 'rgb(171, 149, 113)'],\n",
       "   [37, 82, 'Location', 1, 'rgb(29, 180, 11)'],\n",
       "   [1, 12, 'Name', 0, 'rgb(37, 163, 185)']]}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('train.json','r',encoding='utf8') as f:\n",
    "    TRAIN_DATA=json.loads(f.read())\n",
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# filename = input(\"Enter your train data filename(json) : \")\n",
    "# print(filename)\n",
    "\n",
    "\n",
    "# with open(filename) as train_data:\n",
    "# \ttrain = json.load(train_data)\n",
    "# train\n",
    "TRAIN = []\n",
    "for data in TRAIN_DATA:\n",
    "\tents = [tuple(entity[:3]) for entity in data['entities']]\n",
    "\tTRAIN.append((data['content'],{'entities':ents}))\n",
    "TRAIN_DATA=TRAIN\n",
    "TRAIN_DATA\n",
    "with open('spacy', 'wb') as fp:\n",
    "    pickle.dump(TRAIN_DATA, fp)\n",
    "# with open('{}'.format(filename.replace('json','txt')),'w') as write:\n",
    "# \twrite.write(str(TRAIN_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Iteration: 0\n",
      "Losses {'ner': 3213.263397216797}\n",
      "Iteration: 1\n",
      "Losses {'ner': 3122.6643600463867}\n",
      "Iteration: 2\n",
      "Losses {'ner': 3133.2693634033203}\n",
      "Iteration: 3\n",
      "Losses {'ner': 3051.431800842285}\n",
      "Iteration: 4\n",
      "Losses {'ner': 2934.4107055664062}\n",
      "Iteration: 5\n",
      "Losses {'ner': 2744.7389087677}\n",
      "Iteration: 6\n",
      "Losses {'ner': 2410.683204650879}\n",
      "Iteration: 7\n",
      "Losses {'ner': 1420.7847385406494}\n",
      "Iteration: 8\n",
      "Losses {'ner': 999.3416919708252}\n",
      "Iteration: 9\n",
      "Losses {'ner': 422.7453327178955}\n",
      "Iteration: 10\n",
      "Losses {'ner': 162.73789575695992}\n",
      "Iteration: 11\n",
      "Losses {'ner': 123.62108724936843}\n",
      "Iteration: 12\n",
      "Losses {'ner': 121.31871964759193}\n",
      "Iteration: 13\n",
      "Losses {'ner': 130.6834514082184}\n",
      "Iteration: 14\n",
      "Losses {'ner': 133.13913037028397}\n",
      "Iteration: 15\n",
      "Losses {'ner': 122.76787517329149}\n",
      "Iteration: 16\n",
      "Losses {'ner': 246.11116206645966}\n",
      "Iteration: 17\n",
      "Losses {'ner': 163.89816511789104}\n",
      "Iteration: 18\n",
      "Losses {'ner': 114.57789473360754}\n",
      "Iteration: 19\n",
      "Losses {'ner': 214.33873748779297}\n",
      "Iteration: 20\n",
      "Losses {'ner': 260.5258903503418}\n",
      "Iteration: 21\n",
      "Losses {'ner': 230.1989061832428}\n",
      "Iteration: 22\n",
      "Losses {'ner': 203.2096482515335}\n",
      "Iteration: 23\n",
      "Losses {'ner': 177.5421290397644}\n",
      "Iteration: 24\n",
      "Losses {'ner': 194.65947699546814}\n",
      "Iteration: 25\n",
      "Losses {'ner': 215.08259272575378}\n",
      "Iteration: 26\n",
      "Losses {'ner': 168.33015418052673}\n",
      "Iteration: 27\n",
      "Losses {'ner': 194.1621205508709}\n",
      "Iteration: 28\n",
      "Losses {'ner': 143.1759446784854}\n",
      "Iteration: 29\n",
      "Losses {'ner': 180.90003645420074}\n",
      "Iteration: 30\n",
      "Losses {'ner': 203.47239607572556}\n",
      "Iteration: 31\n",
      "Losses {'ner': 175.43845284171402}\n",
      "Iteration: 32\n",
      "Losses {'ner': 159.50469149649143}\n",
      "Iteration: 33\n",
      "Losses {'ner': 240.14377522468567}\n",
      "Iteration: 34\n",
      "Losses {'ner': 213.975332736969}\n",
      "Iteration: 35\n",
      "Losses {'ner': 133.00800294801593}\n",
      "Iteration: 36\n",
      "Losses {'ner': 249.0528700351715}\n",
      "Iteration: 37\n",
      "Losses {'ner': 192.80934995412827}\n",
      "Iteration: 38\n",
      "Losses {'ner': 265.47962188720703}\n",
      "Iteration: 39\n",
      "Losses {'ner': 163.3930139541626}\n",
      "Iteration: 40\n",
      "Losses {'ner': 138.56414580345154}\n",
      "Iteration: 41\n",
      "Losses {'ner': 121.27787974476814}\n",
      "Iteration: 42\n",
      "Losses {'ner': 225.37388622760773}\n",
      "Iteration: 43\n",
      "Losses {'ner': 193.2897162437439}\n",
      "Iteration: 44\n",
      "Losses {'ner': 151.16563761234283}\n",
      "Iteration: 45\n",
      "Losses {'ner': 112.8761677145958}\n",
      "Iteration: 46\n",
      "Losses {'ner': 137.0389063358307}\n",
      "Iteration: 47\n",
      "Losses {'ner': 105.36102375388145}\n",
      "Iteration: 48\n",
      "Losses {'ner': 135.35461723804474}\n",
      "Iteration: 49\n",
      "Losses {'ner': 124.29690013453364}\n",
      "Iteration: 50\n",
      "Losses {'ner': 217.1247981786728}\n",
      "Iteration: 51\n",
      "Losses {'ner': 165.96135852858424}\n",
      "Iteration: 52\n",
      "Losses {'ner': 92.11384170781821}\n",
      "Iteration: 53\n",
      "Losses {'ner': 101.0481625534594}\n",
      "Iteration: 54\n",
      "Losses {'ner': 213.32678484916687}\n",
      "Iteration: 55\n",
      "Losses {'ner': 182.68982708454132}\n",
      "Iteration: 56\n",
      "Losses {'ner': 103.00275448802859}\n",
      "Iteration: 57\n",
      "Losses {'ner': 89.20634282426909}\n",
      "Iteration: 58\n",
      "Losses {'ner': 132.99521374702454}\n",
      "Iteration: 59\n",
      "Losses {'ner': 123.39107596874237}\n",
      "Iteration: 60\n",
      "Losses {'ner': 86.11191069614142}\n",
      "Iteration: 61\n",
      "Losses {'ner': 96.7410642625764}\n",
      "Iteration: 62\n",
      "Losses {'ner': 147.68985573202372}\n",
      "Iteration: 63\n",
      "Losses {'ner': 89.94772825902328}\n",
      "Iteration: 64\n",
      "Losses {'ner': 94.6834413856268}\n",
      "Iteration: 65\n",
      "Losses {'ner': 83.98017647280358}\n",
      "Iteration: 66\n",
      "Losses {'ner': 89.69333003202337}\n",
      "Iteration: 67\n",
      "Losses {'ner': 89.63478671014309}\n",
      "Iteration: 68\n",
      "Losses {'ner': 102.75421426957473}\n",
      "Iteration: 69\n",
      "Losses {'ner': 110.03910854947753}\n",
      "Iteration: 70\n",
      "Losses {'ner': 122.70944368839264}\n",
      "Iteration: 71\n",
      "Losses {'ner': 118.15912852436304}\n",
      "Iteration: 72\n",
      "Losses {'ner': 172.3153893686831}\n",
      "Iteration: 73\n",
      "Losses {'ner': 130.04315865039825}\n",
      "Iteration: 74\n",
      "Losses {'ner': 207.29881811141968}\n",
      "Iteration: 75\n",
      "Losses {'ner': 171.12147784233093}\n",
      "Iteration: 76\n",
      "Losses {'ner': 103.42264609783888}\n",
      "Iteration: 77\n",
      "Losses {'ner': 159.45503616333008}\n",
      "Iteration: 78\n",
      "Losses {'ner': 124.91532002575696}\n",
      "Iteration: 79\n",
      "Losses {'ner': 93.3281802367419}\n",
      "Iteration: 80\n",
      "Losses {'ner': 115.05450248718262}\n",
      "Iteration: 81\n",
      "Losses {'ner': 76.42896837554872}\n",
      "Iteration: 82\n",
      "Losses {'ner': 81.05025295168161}\n",
      "Iteration: 83\n",
      "Losses {'ner': 79.71316838331404}\n",
      "Iteration: 84\n",
      "Losses {'ner': 185.9107867181301}\n",
      "Iteration: 85\n",
      "Losses {'ner': 98.27216661721468}\n",
      "Iteration: 86\n",
      "Losses {'ner': 84.47776781824359}\n",
      "Iteration: 87\n",
      "Losses {'ner': 87.79847609403078}\n",
      "Iteration: 88\n",
      "Losses {'ner': 92.14246768620797}\n",
      "Iteration: 89\n",
      "Losses {'ner': 151.21248373948038}\n",
      "Iteration: 90\n",
      "Losses {'ner': 151.13400247693062}\n",
      "Iteration: 91\n",
      "Losses {'ner': 275.7170977592468}\n",
      "Iteration: 92\n",
      "Losses {'ner': 230.95971248671412}\n",
      "Iteration: 93\n",
      "Losses {'ner': 205.89428782463074}\n",
      "Iteration: 94\n",
      "Losses {'ner': 231.0703022480011}\n",
      "Iteration: 95\n",
      "Losses {'ner': 247.49803400039673}\n",
      "Iteration: 96\n",
      "Losses {'ner': 519.2016351222992}\n",
      "Iteration: 97\n",
      "Losses {'ner': 313.148907661438}\n",
      "Iteration: 98\n",
      "Losses {'ner': 582.8916547298431}\n",
      "Iteration: 99\n",
      "Losses {'ner': 340.29176330566406}\n",
      "Name -----> AADITYA RAJ\n",
      "Location -----> Indravihar colony ,\n",
      "Lalghati,462030,Bhopal,MP\n",
      "Mob:\n",
      "+917898864576\n",
      "Email:\n",
      "aadityaraj.sistec@gmail.com\n",
      "Web:\n",
      "http://aaditya-blog.surge.sh/\n",
      "LinkedIn:\n",
      "https://www.linkedin.com/in/a\n",
      "aditya-raj-a56426178/\n",
      "Github:\n",
      "https://github.com/Aadityaprit\n",
      "am\n",
      "Objective\n",
      "A dedicated engineer passionate about cutting-edge technology and\n",
      "solving real-world problems with practical exposure. Looking forward to\n",
      "be associated with a dynamic and progressive organization that will allow\n",
      "me to utilize my abilities and qualifications to add value to the\n",
      "organization while providing me opportunities to grow.\n",
      "Work Exposure/ Internship\n",
      "Skills -----> Praemineo\n",
      "Designation -----> Artificial Intelligence Intern at DAURINDIA TECHNOLOGY• Facial\n",
      "Recognition • Facial Verification\n",
      "[ Building Real-time Facial recognition & verification system for the\n",
      "employees of company using Convolutional neural network & OpenCV ]\n",
      "Sep 2019 -Jan 2020\n",
      "\n",
      "Designation -----> Machine Learning Engineer • Chatbot Developer • Emphasis\n",
      "Name -----> Corp\n",
      "Designation -----> Bachelor\n",
      "Skills -----> Natural Language\n",
      "Skills -----> Spacy\n",
      "Skills -----> Deep Learning\n",
      "Skills -----> Python\n",
      "Skills -----> Yolo v3\n",
      "Skills -----> Deep Learning\n",
      "Skills -----> C\n",
      "\n",
      "Skills -----> C++\n",
      "\n",
      "Skills -----> Machine Learning\n",
      "Skills -----> Deep Learning\n",
      "Skills -----> Data Science\n",
      "Skills -----> Computer Vision\n",
      "Skills -----> MySQL Database\n",
      "\n",
      "Skills -----> SQL Lite\n",
      "Skills -----> MongoDB\n",
      "\n",
      " May 2020-June 2020\n",
      "➢ Covid-19 Detection Using X-ray Image:\n",
      "Using X-ray Image ,this model/system predict whether it is\n",
      "positive or negative case with higher accuracy up to 96%, by\n",
      "analyzing X-ray image.\n",
      "\n",
      " March 2020- April 2020\n",
      "➢ Covid-19 Self Assessment System:\n",
      "Predict the %probability of getting infected or not. If result is\n",
      "positive, an automatic mail will be sent to given(health center\n",
      "email)mail . Moreover all the helpline or emergencies functionality\n",
      "are mentioned.\n",
      "Technology Used: Machine Learning\n",
      "Skills -----> Machine Learning\n",
      "Skills -----> Data Science\n",
      "Skills -----> Artificial Intelligence (AI)\n",
      "• Web Application Development\n",
      "Declaration\n",
      "I hereby declare that the above-mentioned information is correct up to my knowledge and I bear the responsibility\n",
      "for the correctness of the above-mentioned particulars.\n",
      " Signature\n",
      " (Aaditya Raj)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import pickle\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "# New entity labels\n",
    "# Specify the new entity labels which you want to add here\n",
    "LABEL = ['Name', 'Email', 'Phone No', 'Companies worked at','Designation','Year of experience','Location','Skills','Education']\n",
    "\n",
    "# Loading training data \n",
    "with open ('spacy', 'rb') as fp:\n",
    "    TRAIN_DATA = pickle.load(fp)\n",
    "\n",
    "\n",
    "# @plac.annotations(\n",
    "#     model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
    "#     new_model_name=(\"New model name for model meta.\", \"option\", \"nm\", str),\n",
    "#     output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
    "#     n_iter=(\"Number of training iterations\", \"option\", \"n\", int))\n",
    "\n",
    "def main(model=None, new_model_name='new_model', output_dir='./', n_iter=100):\n",
    "    \"\"\"Setting up the pipeline and entity recognizer, and training the new entity.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spacy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank('en')  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner)\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "    for i in LABEL:\n",
    "        ner.add_label(i)   # Add new entity labels to entity recognizer\n",
    "\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.entity.create_optimizer()\n",
    "\n",
    "    # Get names of other pipes to disable them during training to train only NER\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            batches = minibatch(TRAIN_DATA, size=compounding(4., 32., 1.001))\n",
    "            for batch in batches:\n",
    "                [texts, annotations] = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35,\n",
    "                           losses=losses)\n",
    "            print(\"Iteration:\",itn)\n",
    "            print('Losses', losses)\n",
    "\n",
    "    # Test the trained model\n",
    "    test_text = ''' AADITYA RAJ\n",
    "Contact\n",
    "Address:\n",
    "A-281, Indravihar colony ,\n",
    "Lalghati,462030,Bhopal,MP\n",
    "Mob:\n",
    "+917898864576\n",
    "Email:\n",
    "aadityaraj.sistec@gmail.com\n",
    "Web:\n",
    "http://aaditya-blog.surge.sh/\n",
    "LinkedIn:\n",
    "https://www.linkedin.com/in/a\n",
    "aditya-raj-a56426178/\n",
    "Github:\n",
    "https://github.com/Aadityaprit\n",
    "am\n",
    "Objective\n",
    "A dedicated engineer passionate about cutting-edge technology and\n",
    "solving real-world problems with practical exposure. Looking forward to\n",
    "be associated with a dynamic and progressive organization that will allow\n",
    "me to utilize my abilities and qualifications to add value to the\n",
    "organization while providing me opportunities to grow.\n",
    "Work Exposure/ Internship\n",
    "Sep 2020 - Present\n",
    "Machine Learning Intern • Praemineo, Inc.\n",
    "[ I help Machine Learning & Deep Learning teams building scalable\n",
    "product with the cutting edge technologies best practices.]\n",
    "June 2020-sep 2020\n",
    "Artificial Intelligence Intern at DAURINDIA TECHNOLOGY• Facial\n",
    "Recognition • Facial Verification\n",
    "[ Building Real-time Facial recognition & verification system for the\n",
    "employees of company using Convolutional neural network & OpenCV ]\n",
    "Sep 2019 -Jan 2020\n",
    "Machine Learning Engineer • Chatbot Developer • Emphasis Corp\n",
    "[ Developed a chatbot for resolving normal IT-issues related to Pc and\n",
    "laptops using Dialogflow . Worked on a team of five member]\n",
    "Education\n",
    "Bachelor of Engineering - Sagar\n",
    "Institute of Science and\n",
    "Technology (SISTec), Bhopal\n",
    "06/2017 – Present\n",
    "➢ CGPA: 8.6\n",
    "Higher Secondary - Trident\n",
    "Public School,\n",
    "Muzaffarpur,04/2015 –07/2017\n",
    "➢ Percentage: 74.8%\n",
    "Projects\n",
    " Dec 2020-Jan 2021\n",
    "➢ Custom Named Entity Recognition:\n",
    "Developed a System for the text recognition and tagging for\n",
    "custom type of text. Technologies used are- Natural Language\n",
    "Processing, Spacy, Deep Learning, Python.\n",
    " July 2020-July 2020\n",
    "➢ Damage Detection System:\n",
    "Detecting the various types of Damages like-Cracks, Bullseyes,\n",
    "Scratches, etc. using Yolo v3 & Deep Learning technology. This\n",
    "system helps in identifying the types of damage and localize them\n",
    "with the help of which, it becomes very easy to analyze the cost\n",
    "of rapairing.\n",
    " \n",
    "Senior Secondary – Emmanuel\n",
    "School, Motihari 04/2014 –\n",
    "07/2015\n",
    "➢ CGPA: 10.0\n",
    "Key Skills\n",
    "• Python\n",
    "• C\n",
    "• C++\n",
    "• Machine Learning\n",
    "• Deep Learning\n",
    "• Data Science\n",
    "• Computer Vision\n",
    "• MySQL Database\n",
    "• SQL Lite\n",
    "• Flask\n",
    "• MongoDB\n",
    "\n",
    " May 2020-June 2020\n",
    "➢ Covid-19 Detection Using X-ray Image:\n",
    "Using X-ray Image ,this model/system predict whether it is\n",
    "positive or negative case with higher accuracy up to 96%, by\n",
    "analyzing X-ray image.\n",
    "\n",
    " March 2020- April 2020\n",
    "➢ Covid-19 Self Assessment System:\n",
    "Predict the %probability of getting infected or not. If result is\n",
    "positive, an automatic mail will be sent to given(health center\n",
    "email)mail . Moreover all the helpline or emergencies functionality\n",
    "are mentioned.\n",
    "Technology Used: Machine Learning, Flask\n",
    "Web: https://covid-19-self-assessment.herokuapp.com/\n",
    "App: http://aadityapritam.thehacktivist.tech/\n",
    " May 2020-June 2020\n",
    "➢ Emotion Detection & Classification Using Face Image\n",
    "Developed an Emotion Detection Deep Learning Model using\n",
    "Convolutional neural network to identify Happy or Sad using\n",
    "Person’s Image.\n",
    "\n",
    " Jan 2020 -April 2020\n",
    "➢ Auto-Image-Captioning :\n",
    "Describe or recognize the activity of image and provide an\n",
    "automatic caption to the given image\n",
    "Technology Used: Deep Learning(CNN) , Flask\n",
    " Oct 2019 -Dec 2019\n",
    "➢ Carrier-Consultancy-System:\n",
    "Suggest Job fields for Computer Science Students based on\n",
    "their skill quotients by recognize or extract skills from resume\n",
    "Technology Use: Machine Learning, Natural LanguageProcessing, Flask\n",
    "\n",
    " Sep 2019 -Sep 2019\n",
    "➢ Library Management System:\n",
    "A reliable Library System where all the records and functions is\n",
    "workable\n",
    "Technology Used: Python , File Management\n",
    "Certificates/Trainings\n",
    "➢ Convolutional Neural Networks.\n",
    "➢ A Crash Course in Data Science.\n",
    "\n",
    "➢ Image Data Augmentation with Keras.\n",
    "➢ IBM Certificate for Machine Learning using Python\n",
    "https://www.coursera.org/account/accomplishments/records/58W\n",
    "E27BYTNNZ\n",
    "➢ Data Science Methodology certificate by Coursera\n",
    "https://www.coursera.org/account/accomplishments/certificate/V5\n",
    "Q4W2S2DQGT\n",
    "➢ Advance Python Training at SISTec\n",
    "➢ Introduction To Python at Datacamp :\n",
    "https://www.datacamp.com/statement-ofaccomplishment/course/2b2ccbd2fbd3d6a91921907d243633d8e\n",
    "e9f2ccc\n",
    "Achievements\n",
    " • Code Gladiator 2019 Semifinalist .\n",
    "• Qualfied Google Codejam 2019 & 2020( Qualifier Round)\n",
    "• 98.37% skill quotient in python on Techgig\n",
    "• Gold Badge holder in 30days of code on Hackerrank\n",
    "https://www.hackerrank.com/aadityaraj_sist1\n",
    "• Hackerearth https://www.hackerearth.com/@aaditya50\n",
    "Area Of Interests\n",
    "• Deep Learning\n",
    "• Machine Learning\n",
    "• Data Science\n",
    "• Internet Of things(IOT)\n",
    "• Artificial Intelligence (AI)\n",
    "• Web Application Development\n",
    "Declaration\n",
    "I hereby declare that the above-mentioned information is correct up to my knowledge and I bear the responsibility\n",
    "for the correctness of the above-mentioned particulars.\n",
    " Signature\n",
    " (Aaditya Raj)'''\n",
    "    doc = nlp(test_text)\n",
    "#     print(\"Entities in '%s'\" % test_text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.label_,'----->',ent.text)\n",
    "\n",
    "    # Save model \n",
    "#     if output_dir is not None:\n",
    "#         output_dir = Path(output_dir)\n",
    "#         if not output_dir.exists():\n",
    "#             output_dir.mkdir()\n",
    "#         nlp.meta['name'] = new_model_name  # rename model\n",
    "#         nlp.to_disk(output_dir)\n",
    "#         print(\"Saved model to\", output_dir)\n",
    "\n",
    "#         # Test the saved model\n",
    "#         print(\"Loading from\", output_dir)\n",
    "#         nlp2 = spacy.load(output_dir)\n",
    "#         doc2 = nlp2(test_text)\n",
    "#         for ent in doc2.ents:\n",
    "#             print(ent.label_,'----->', ent.text)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"NEW_MODEL\")\n",
    "doc = nlp(test_text)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "nlp2 = spacy.load('NER_MODEL_2oct/NER_MODEL_2oct')\n",
    "assert nlp2.get_pipe(\"ner\")\n",
    "ind=1\n",
    "for ref in var:\n",
    "    doc2 = nlp2(ref)\n",
    "    with open('test_Model_4oct_101.tsv','a') as f:\n",
    "        f.write(ref)\n",
    "#         print(str(ind)+'\\t'+ref)\n",
    "        ind+=1\n",
    "        for ent in doc2.ents:\n",
    "            print(ent.text,'------->',ent.label_)\n",
    "            f.writelines('\\t'+ent.text+\"\\t\"+ent.label_+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ''' AADITYA RAJ\n",
    "Contact\n",
    "Address:\n",
    "A-281, Indravihar colony ,\n",
    "Lalghati,462030,Bhopal,MP\n",
    "Mob:\n",
    "+917898864576\n",
    "Email:\n",
    "aadityaraj.sistec@gmail.com\n",
    "Web:\n",
    "http://aaditya-blog.surge.sh/\n",
    "LinkedIn:\n",
    "https://www.linkedin.com/in/a\n",
    "aditya-raj-a56426178/\n",
    "Github:\n",
    "https://github.com/Aadityaprit\n",
    "am\n",
    "Objective\n",
    "A dedicated engineer passionate about cutting-edge technology and\n",
    "solving real-world problems with practical exposure. Looking forward to\n",
    "be associated with a dynamic and progressive organization that will allow\n",
    "me to utilize my abilities and qualifications to add value to the\n",
    "organization while providing me opportunities to grow.\n",
    "Work Exposure/ Internship\n",
    "Sep 2020 - Present\n",
    "Machine Learning Intern • Praemineo, Inc.\n",
    "[ I help Machine Learning & Deep Learning teams building scalable\n",
    "product with the cutting edge technologies best practices.]\n",
    "June 2020-sep 2020\n",
    "Artificial Intelligence Intern at DAURINDIA TECHNOLOGY• Facial\n",
    "Recognition • Facial Verification\n",
    "[ Building Real-time Facial recognition & verification system for the\n",
    "employees of company using Convolutional neural network & OpenCV ]\n",
    "Sep 2019 -Jan 2020\n",
    "Machine Learning Engineer • Chatbot Developer • Emphasis Corp\n",
    "[ Developed a chatbot for resolving normal IT-issues related to Pc and\n",
    "laptops using Dialogflow . Worked on a team of five member]\n",
    "Education\n",
    "Bachelor of Engineering - Sagar\n",
    "Institute of Science and\n",
    "Technology (SISTec), Bhopal\n",
    "06/2017 – Present\n",
    "➢ CGPA: 8.6\n",
    "Higher Secondary - Trident\n",
    "Public School,\n",
    "Muzaffarpur,04/2015 –07/2017\n",
    "➢ Percentage: 74.8%\n",
    "Projects\n",
    " Dec 2020-Jan 2021\n",
    "➢ Custom Named Entity Recognition:\n",
    "Developed a System for the text recognition and tagging for\n",
    "custom type of text. Technologies used are- Natural Language\n",
    "Processing, Spacy, Deep Learning, Python.\n",
    " July 2020-July 2020\n",
    "➢ Damage Detection System:\n",
    "Detecting the various types of Damages like-Cracks, Bullseyes,\n",
    "Scratches, etc. using Yolo v3 & Deep Learning technology. This\n",
    "system helps in identifying the types of damage and localize them\n",
    "with the help of which, it becomes very easy to analyze the cost\n",
    "of rapairing.\n",
    " \n",
    "Senior Secondary – Emmanuel\n",
    "School, Motihari 04/2014 –\n",
    "07/2015\n",
    "➢ CGPA: 10.0\n",
    "Key Skills\n",
    "• Python\n",
    "• C\n",
    "• C++\n",
    "• Machine Learning\n",
    "• Deep Learning\n",
    "• Data Science\n",
    "• Computer Vision\n",
    "• MySQL Database\n",
    "• SQL Lite\n",
    "• Flask\n",
    "• MongoDB\n",
    "\n",
    " May 2020-June 2020\n",
    "➢ Covid-19 Detection Using X-ray Image:\n",
    "Using X-ray Image ,this model/system predict whether it is\n",
    "positive or negative case with higher accuracy up to 96%, by\n",
    "analyzing X-ray image.\n",
    "\n",
    " March 2020- April 2020\n",
    "➢ Covid-19 Self Assessment System:\n",
    "Predict the %probability of getting infected or not. If result is\n",
    "positive, an automatic mail will be sent to given(health center\n",
    "email)mail . Moreover all the helpline or emergencies functionality\n",
    "are mentioned.\n",
    "Technology Used: Machine Learning, Flask\n",
    "Web: https://covid-19-self-assessment.herokuapp.com/\n",
    "App: http://aadityapritam.thehacktivist.tech/\n",
    " May 2020-June 2020\n",
    "➢ Emotion Detection & Classification Using Face Image\n",
    "Developed an Emotion Detection Deep Learning Model using\n",
    "Convolutional neural network to identify Happy or Sad using\n",
    "Person’s Image.\n",
    "\n",
    " Jan 2020 -April 2020\n",
    "➢ Auto-Image-Captioning :\n",
    "Describe or recognize the activity of image and provide an\n",
    "automatic caption to the given image\n",
    "Technology Used: Deep Learning(CNN) , Flask\n",
    " Oct 2019 -Dec 2019\n",
    "➢ Carrier-Consultancy-System:\n",
    "Suggest Job fields for Computer Science Students based on\n",
    "their skill quotients by recognize or extract skills from resume\n",
    "Technology Use: Machine Learning, Natural LanguageProcessing, Flask\n",
    "\n",
    " Sep 2019 -Sep 2019\n",
    "➢ Library Management System:\n",
    "A reliable Library System where all the records and functions is\n",
    "workable\n",
    "Technology Used: Python , File Management\n",
    "Certificates/Trainings\n",
    "➢ Convolutional Neural Networks.\n",
    "➢ A Crash Course in Data Science.\n",
    "\n",
    "➢ Image Data Augmentation with Keras.\n",
    "➢ IBM Certificate for Machine Learning using Python\n",
    "https://www.coursera.org/account/accomplishments/records/58W\n",
    "E27BYTNNZ\n",
    "➢ Data Science Methodology certificate by Coursera\n",
    "https://www.coursera.org/account/accomplishments/certificate/V5\n",
    "Q4W2S2DQGT\n",
    "➢ Advance Python Training at SISTec\n",
    "➢ Introduction To Python at Datacamp :\n",
    "https://www.datacamp.com/statement-ofaccomplishment/course/2b2ccbd2fbd3d6a91921907d243633d8e\n",
    "e9f2ccc\n",
    "Achievements\n",
    " • Code Gladiator 2019 Semifinalist .\n",
    "• Qualfied Google Codejam 2019 & 2020( Qualifier Round)\n",
    "• 98.37% skill quotient in python on Techgig\n",
    "• Gold Badge holder in 30days of code on Hackerrank\n",
    "https://www.hackerrank.com/aadityaraj_sist1\n",
    "• Hackerearth https://www.hackerearth.com/@aaditya50\n",
    "Area Of Interests\n",
    "• Deep Learning\n",
    "• Machine Learning\n",
    "• Data Science\n",
    "• Internet Of things(IOT)\n",
    "• Artificial Intelligence (AI)\n",
    "• Web Application Development\n",
    "Declaration\n",
    "I hereby declare that the above-mentioned information is correct up to my knowledge and I bear the responsibility\n",
    "for the correctness of the above-mentioned particulars.\n",
    " Signature\n",
    " (Aaditya Raj)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bita6c99014a5af4e34a90c673f1e7a967f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
